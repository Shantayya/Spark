{"cells":[{"cell_type":"code","source":["#DataFrames are wrapper on rdd.\n#we create SparkSession for spark to read data in dataframe format. where as for SparkContext, spark read the data in rdd format.\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.appName(\"Spark DataFrames\").getOrCreate()\ndf = spark.read.option(\"header\",True).csv(\"/FileStore/tables/studentDatat.csv\")\ndf.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"07c77458-f783-4a55-8ac2-130cf1220017","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+------+-----------------+--------------+----+-----+--------------------+\n|age|gender|             name|        course|roll|marks|               email|\n+---+------+-----------------+--------------+----+-----+--------------------+\n| 22|     F|        Kiana Lor|    Data Enggg| 101|  100|  KianaLor@gmail.com|\n| 22|     M|   Joshua Lonaker|   Cloud Admin| 102|   99|JoshuaLonaker@gma...|\n| 22|     F|    Dakota Blanco|        DevOps| 103|   65|DakotaBlanco@gmai...|\n| 20|     F|  Natasha Yarusso|     FullStack| 104|   78|NatashaYarusso@gm...|\n| 21|     F|   Brooke Cazares|         MLOps| 105|   98|BrookeCazares@gma...|\n| 21|     F| Rochelle Johnson|data Scientist| 106|   54|RochelleJohnson@g...|\n| 22|     M|       Joey Abreu|      FrontEnd| 107|   63| JoeyAbreu@gmail.com|\n| 22|     M|   Preston Suarez|       Backend| 108|   48|PrestonSuarez@gma...|\n| 24|     F|         Lee Dong|         UI/UX| 109|   87|   LeeDong@gmail.com|\n| 22|     M|    Maa'iz al-Dia|           SRE| 110|   69|Maa'izal-Dia@gmai...|\n| 23|     F|   Maja Nicholson|  Network engg| 111|   57|MajaNicholson@gma...|\n| 21|     F|     Sasha Jansen| Security Engg| 112|   99|SashaJansen@gmail...|\n| 20|     M|Alexander Sherman|    Data Enggg| 113|   65|AlexanderSherman@...|\n| 23|     M|    Edgar Sanchez|   Cloud Admin| 114|   78|EdgarSanchez@gmai...|\n| 21|     M|     Kolbi Strunk|        DevOps| 115|   98|KolbiStrunk@gmail...|\n| 21|     F|    Brittany Sath|     FullStack| 116|   54|BrittanySath@gmai...|\n| 21|     F|     Meggan Smith|         MLOps| 117|   63|MegganSmith@gmail...|\n| 23| other|   Ericka Arreola|data Scientist| 118|   48|ErickaArreola@gma...|\n| 24|     M|       David Pulc|      FrontEnd| 119|   87| DavidPulc@gmail.com|\n| 23|     M|      Kyle Luckey|       Backend| 120|   69|KyleLuckey@gmail.com|\n+---+------+-----------------+--------------+----+-----+--------------------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#If we could not include inferSchema in options then spark will consider all data types as string. \ndf.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"318fbec1-137f-4ac7-ba01-780aacf43d94","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- age: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- name: string (nullable = true)\n |-- course: string (nullable = true)\n |-- roll: string (nullable = true)\n |-- marks: string (nullable = true)\n |-- email: string (nullable = true)\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#instead of writing multiple option() functions we can write options(key='value') format\ndf = spark.read.options(header='True', inferSchema='True').csv(\"/FileStore/tables/studentDatat.csv\")\ndf.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"449d2487-2cfd-4816-994c-e0a8a38de438","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- age: integer (nullable = true)\n |-- gender: string (nullable = true)\n |-- name: string (nullable = true)\n |-- course: string (nullable = true)\n |-- roll: integer (nullable = true)\n |-- marks: integer (nullable = true)\n |-- email: string (nullable = true)\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#create our own schema using StructType and StructField\nfrom pyspark.sql.types import StructType, StructField, IntegerType,StringType\nschema = StructType([\n    StructField('age',IntegerType(),True),\n    StructField('gender',StringType(),True),\n    StructField('name',StringType(),True),\n    StructField('course',StringType(),True),\n    StructField('roll',StringType(),True),\n    StructField('marks',IntegerType(),True),\n    StructField('email',StringType(),True)\n])\ndf = spark.read.options(header=\"True\").schema(schema).csv(\"/FileStore/tables/studentDatat.csv\")\ndf.show()\ndf.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"cb02426b-3a21-4410-a7b4-7828f6dfefb6","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+------+-----------------+--------------+----+-----+--------------------+\n|age|gender|             name|        course|roll|marks|               email|\n+---+------+-----------------+--------------+----+-----+--------------------+\n| 22|     F|        Kiana Lor|    Data Enggg| 101|  100|  KianaLor@gmail.com|\n| 22|     M|   Joshua Lonaker|   Cloud Admin| 102|   99|JoshuaLonaker@gma...|\n| 22|     F|    Dakota Blanco|        DevOps| 103|   65|DakotaBlanco@gmai...|\n| 20|     F|  Natasha Yarusso|     FullStack| 104|   78|NatashaYarusso@gm...|\n| 21|     F|   Brooke Cazares|         MLOps| 105|   98|BrookeCazares@gma...|\n| 21|     F| Rochelle Johnson|data Scientist| 106|   54|RochelleJohnson@g...|\n| 22|     M|       Joey Abreu|      FrontEnd| 107|   63| JoeyAbreu@gmail.com|\n| 22|     M|   Preston Suarez|       Backend| 108|   48|PrestonSuarez@gma...|\n| 24|     F|         Lee Dong|         UI/UX| 109|   87|   LeeDong@gmail.com|\n| 22|     M|    Maa'iz al-Dia|           SRE| 110|   69|Maa'izal-Dia@gmai...|\n| 23|     F|   Maja Nicholson|  Network engg| 111|   57|MajaNicholson@gma...|\n| 21|     F|     Sasha Jansen| Security Engg| 112|   99|SashaJansen@gmail...|\n| 20|     M|Alexander Sherman|    Data Enggg| 113|   65|AlexanderSherman@...|\n| 23|     M|    Edgar Sanchez|   Cloud Admin| 114|   78|EdgarSanchez@gmai...|\n| 21|     M|     Kolbi Strunk|        DevOps| 115|   98|KolbiStrunk@gmail...|\n| 21|     F|    Brittany Sath|     FullStack| 116|   54|BrittanySath@gmai...|\n| 21|     F|     Meggan Smith|         MLOps| 117|   63|MegganSmith@gmail...|\n| 23| other|   Ericka Arreola|data Scientist| 118|   48|ErickaArreola@gma...|\n| 24|     M|       David Pulc|      FrontEnd| 119|   87| DavidPulc@gmail.com|\n| 23|     M|      Kyle Luckey|       Backend| 120|   69|KyleLuckey@gmail.com|\n+---+------+-----------------+--------------+----+-----+--------------------+\nonly showing top 20 rows\n\nroot\n |-- age: integer (nullable = true)\n |-- gender: string (nullable = true)\n |-- name: string (nullable = true)\n |-- course: string (nullable = true)\n |-- roll: string (nullable = true)\n |-- marks: integer (nullable = true)\n |-- email: string (nullable = true)\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#creating plane DataFrame from rdd\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.appName(\"DftoRdd\").getOrCreate()\n\nfrom pyspark import SparkConf,SparkContext\n# conf = SparkConf().setAppName(\"dataframeTordd\")\n# sc = SparkContext().getOrCreate(conf = conf)\nrdd = sc.textFile(\"/FileStore/tables/studentDatat.csv\")\nheaders = rdd.first()\nrdd = rdd.filter(lambda x:x != headers).map(lambda x:x.split(\",\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"74eeb4f7-1795-471e-957b-ea4cc12f375c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["dfrdd = rdd.toDF()\ndfrdd.show()\ndfrdd.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"afc88166-b727-45d2-89a4-0fe33bd333c5","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+-----+-----------------+--------------+---+---+--------------------+\n| _1|   _2|               _3|            _4| _5| _6|                  _7|\n+---+-----+-----------------+--------------+---+---+--------------------+\n| 22|    F|        Kiana Lor|    Data Enggg|101|100|  KianaLor@gmail.com|\n| 22|    M|   Joshua Lonaker|   Cloud Admin|102| 99|JoshuaLonaker@gma...|\n| 22|    F|    Dakota Blanco|        DevOps|103| 65|DakotaBlanco@gmai...|\n| 20|    F|  Natasha Yarusso|     FullStack|104| 78|NatashaYarusso@gm...|\n| 21|    F|   Brooke Cazares|         MLOps|105| 98|BrookeCazares@gma...|\n| 21|    F| Rochelle Johnson|data Scientist|106| 54|RochelleJohnson@g...|\n| 22|    M|       Joey Abreu|      FrontEnd|107| 63| JoeyAbreu@gmail.com|\n| 22|    M|   Preston Suarez|       Backend|108| 48|PrestonSuarez@gma...|\n| 24|    F|         Lee Dong|         UI/UX|109| 87|   LeeDong@gmail.com|\n| 22|    M|    Maa'iz al-Dia|           SRE|110| 69|Maa'izal-Dia@gmai...|\n| 23|    F|   Maja Nicholson|  Network engg|111| 57|MajaNicholson@gma...|\n| 21|    F|     Sasha Jansen| Security Engg|112| 99|SashaJansen@gmail...|\n| 20|    M|Alexander Sherman|    Data Enggg|113| 65|AlexanderSherman@...|\n| 23|    M|    Edgar Sanchez|   Cloud Admin|114| 78|EdgarSanchez@gmai...|\n| 21|    M|     Kolbi Strunk|        DevOps|115| 98|KolbiStrunk@gmail...|\n| 21|    F|    Brittany Sath|     FullStack|116| 54|BrittanySath@gmai...|\n| 21|    F|     Meggan Smith|         MLOps|117| 63|MegganSmith@gmail...|\n| 23|other|   Ericka Arreola|data Scientist|118| 48|ErickaArreola@gma...|\n| 24|    M|       David Pulc|      FrontEnd|119| 87| DavidPulc@gmail.com|\n| 23|    M|      Kyle Luckey|       Backend|120| 69|KyleLuckey@gmail.com|\n+---+-----+-----------------+--------------+---+---+--------------------+\nonly showing top 20 rows\n\nroot\n |-- _1: string (nullable = true)\n |-- _2: string (nullable = true)\n |-- _3: string (nullable = true)\n |-- _4: string (nullable = true)\n |-- _5: string (nullable = true)\n |-- _6: string (nullable = true)\n |-- _7: string (nullable = true)\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#creating DataFrame with column names from rdd\nfrom pyspark.sql.types import StructType, StructField, IntegerType,StringType\nschema = StructType([\n    StructField('age',IntegerType(),True),\n    StructField('gender',StringType(),True),\n    StructField('name',StringType(),True),\n    StructField('course',StringType(),True),\n    StructField('roll',StringType(),True),\n    StructField('marks',IntegerType(),True),\n    StructField('email',StringType(),True)\n])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"73da2ee7-5dde-428d-a8e1-32dd144bef51","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["columns = headers.split(',')\ndfrdd = rdd.toDF(columns)\ndfrdd.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"eaacf6ba-ab67-4839-8124-388967031636","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+------+-----------------+--------------+----+-----+--------------------+\n|age|gender|             name|        course|roll|marks|               email|\n+---+------+-----------------+--------------+----+-----+--------------------+\n| 22|     F|        Kiana Lor|    Data Enggg| 101|  100|  KianaLor@gmail.com|\n| 22|     M|   Joshua Lonaker|   Cloud Admin| 102|   99|JoshuaLonaker@gma...|\n| 22|     F|    Dakota Blanco|        DevOps| 103|   65|DakotaBlanco@gmai...|\n| 20|     F|  Natasha Yarusso|     FullStack| 104|   78|NatashaYarusso@gm...|\n| 21|     F|   Brooke Cazares|         MLOps| 105|   98|BrookeCazares@gma...|\n| 21|     F| Rochelle Johnson|data Scientist| 106|   54|RochelleJohnson@g...|\n| 22|     M|       Joey Abreu|      FrontEnd| 107|   63| JoeyAbreu@gmail.com|\n| 22|     M|   Preston Suarez|       Backend| 108|   48|PrestonSuarez@gma...|\n| 24|     F|         Lee Dong|         UI/UX| 109|   87|   LeeDong@gmail.com|\n| 22|     M|    Maa'iz al-Dia|           SRE| 110|   69|Maa'izal-Dia@gmai...|\n| 23|     F|   Maja Nicholson|  Network engg| 111|   57|MajaNicholson@gma...|\n| 21|     F|     Sasha Jansen| Security Engg| 112|   99|SashaJansen@gmail...|\n| 20|     M|Alexander Sherman|    Data Enggg| 113|   65|AlexanderSherman@...|\n| 23|     M|    Edgar Sanchez|   Cloud Admin| 114|   78|EdgarSanchez@gmai...|\n| 21|     M|     Kolbi Strunk|        DevOps| 115|   98|KolbiStrunk@gmail...|\n| 21|     F|    Brittany Sath|     FullStack| 116|   54|BrittanySath@gmai...|\n| 21|     F|     Meggan Smith|         MLOps| 117|   63|MegganSmith@gmail...|\n| 23| other|   Ericka Arreola|data Scientist| 118|   48|ErickaArreola@gma...|\n| 24|     M|       David Pulc|      FrontEnd| 119|   87| DavidPulc@gmail.com|\n| 23|     M|      Kyle Luckey|       Backend| 120|   69|KyleLuckey@gmail.com|\n+---+------+-----------------+--------------+----+-----+--------------------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#create dataframe with schema from rdd\ndf = spark.createDataFrame(rdd, schema = schema)\ndf.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"30c33eed-ead1-4977-a2c3-8731a3703555","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- age: integer (nullable = true)\n |-- gender: string (nullable = true)\n |-- name: string (nullable = true)\n |-- course: string (nullable = true)\n |-- roll: string (nullable = true)\n |-- marks: integer (nullable = true)\n |-- email: string (nullable = true)\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#diff ways of fetching columns from dataframe\ndf = spark.read.options(header='True',inferSchema='True').csv(\"/FileStore/tables/studentDatat.csv\")\ndf.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"8ebf454d-e37d-4e1c-9267-771a5477c592","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+------+-----------------+--------------+----+-----+--------------------+\n|age|gender|             name|        course|roll|marks|               email|\n+---+------+-----------------+--------------+----+-----+--------------------+\n| 22|     F|        Kiana Lor|    Data Enggg| 101|  100|  KianaLor@gmail.com|\n| 22|     M|   Joshua Lonaker|   Cloud Admin| 102|   99|JoshuaLonaker@gma...|\n| 22|     F|    Dakota Blanco|        DevOps| 103|   65|DakotaBlanco@gmai...|\n| 20|     F|  Natasha Yarusso|     FullStack| 104|   78|NatashaYarusso@gm...|\n| 21|     F|   Brooke Cazares|         MLOps| 105|   98|BrookeCazares@gma...|\n| 21|     F| Rochelle Johnson|data Scientist| 106|   54|RochelleJohnson@g...|\n| 22|     M|       Joey Abreu|      FrontEnd| 107|   63| JoeyAbreu@gmail.com|\n| 22|     M|   Preston Suarez|       Backend| 108|   48|PrestonSuarez@gma...|\n| 24|     F|         Lee Dong|         UI/UX| 109|   87|   LeeDong@gmail.com|\n| 22|     M|    Maa'iz al-Dia|           SRE| 110|   69|Maa'izal-Dia@gmai...|\n| 23|     F|   Maja Nicholson|  Network engg| 111|   57|MajaNicholson@gma...|\n| 21|     F|     Sasha Jansen| Security Engg| 112|   99|SashaJansen@gmail...|\n| 20|     M|Alexander Sherman|    Data Enggg| 113|   65|AlexanderSherman@...|\n| 23|     M|    Edgar Sanchez|   Cloud Admin| 114|   78|EdgarSanchez@gmai...|\n| 21|     M|     Kolbi Strunk|        DevOps| 115|   98|KolbiStrunk@gmail...|\n| 21|     F|    Brittany Sath|     FullStack| 116|   54|BrittanySath@gmai...|\n| 21|     F|     Meggan Smith|         MLOps| 117|   63|MegganSmith@gmail...|\n| 23| other|   Ericka Arreola|data Scientist| 118|   48|ErickaArreola@gma...|\n| 24|     M|       David Pulc|      FrontEnd| 119|   87| DavidPulc@gmail.com|\n| 23|     M|      Kyle Luckey|       Backend| 120|   69|KyleLuckey@gmail.com|\n+---+------+-----------------+--------------+----+-----+--------------------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#access all coumns\ndf.select('*').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"69de8832-93de-4a6b-a8be-fcf45e7789a1","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+------+-----------------+--------------+----+-----+--------------------+\n|age|gender|             name|        course|roll|marks|               email|\n+---+------+-----------------+--------------+----+-----+--------------------+\n| 22|     F|        Kiana Lor|    Data Enggg| 101|  100|  KianaLor@gmail.com|\n| 22|     M|   Joshua Lonaker|   Cloud Admin| 102|   99|JoshuaLonaker@gma...|\n| 22|     F|    Dakota Blanco|        DevOps| 103|   65|DakotaBlanco@gmai...|\n| 20|     F|  Natasha Yarusso|     FullStack| 104|   78|NatashaYarusso@gm...|\n| 21|     F|   Brooke Cazares|         MLOps| 105|   98|BrookeCazares@gma...|\n| 21|     F| Rochelle Johnson|data Scientist| 106|   54|RochelleJohnson@g...|\n| 22|     M|       Joey Abreu|      FrontEnd| 107|   63| JoeyAbreu@gmail.com|\n| 22|     M|   Preston Suarez|       Backend| 108|   48|PrestonSuarez@gma...|\n| 24|     F|         Lee Dong|         UI/UX| 109|   87|   LeeDong@gmail.com|\n| 22|     M|    Maa'iz al-Dia|           SRE| 110|   69|Maa'izal-Dia@gmai...|\n| 23|     F|   Maja Nicholson|  Network engg| 111|   57|MajaNicholson@gma...|\n| 21|     F|     Sasha Jansen| Security Engg| 112|   99|SashaJansen@gmail...|\n| 20|     M|Alexander Sherman|    Data Enggg| 113|   65|AlexanderSherman@...|\n| 23|     M|    Edgar Sanchez|   Cloud Admin| 114|   78|EdgarSanchez@gmai...|\n| 21|     M|     Kolbi Strunk|        DevOps| 115|   98|KolbiStrunk@gmail...|\n| 21|     F|    Brittany Sath|     FullStack| 116|   54|BrittanySath@gmai...|\n| 21|     F|     Meggan Smith|         MLOps| 117|   63|MegganSmith@gmail...|\n| 23| other|   Ericka Arreola|data Scientist| 118|   48|ErickaArreola@gma...|\n| 24|     M|       David Pulc|      FrontEnd| 119|   87| DavidPulc@gmail.com|\n| 23|     M|      Kyle Luckey|       Backend| 120|   69|KyleLuckey@gmail.com|\n+---+------+-----------------+--------------+----+-----+--------------------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#access few columns\ndf.select('age','gender','name').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"2b7f2ec2-d561-4400-8e19-da4b0c95fe04","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+------+-----------------+\n|age|gender|             name|\n+---+------+-----------------+\n| 22|     F|        Kiana Lor|\n| 22|     M|   Joshua Lonaker|\n| 22|     F|    Dakota Blanco|\n| 20|     F|  Natasha Yarusso|\n| 21|     F|   Brooke Cazares|\n| 21|     F| Rochelle Johnson|\n| 22|     M|       Joey Abreu|\n| 22|     M|   Preston Suarez|\n| 24|     F|         Lee Dong|\n| 22|     M|    Maa'iz al-Dia|\n| 23|     F|   Maja Nicholson|\n| 21|     F|     Sasha Jansen|\n| 20|     M|Alexander Sherman|\n| 23|     M|    Edgar Sanchez|\n| 21|     M|     Kolbi Strunk|\n| 21|     F|    Brittany Sath|\n| 21|     F|     Meggan Smith|\n| 23| other|   Ericka Arreola|\n| 24|     M|       David Pulc|\n| 23|     M|      Kyle Luckey|\n+---+------+-----------------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["df.select(df.name,df.age).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"59f364d4-40b2-48d4-afd7-c9ab9813250d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-----------------+---+\n|             name|age|\n+-----------------+---+\n|        Kiana Lor| 22|\n|   Joshua Lonaker| 22|\n|    Dakota Blanco| 22|\n|  Natasha Yarusso| 20|\n|   Brooke Cazares| 21|\n| Rochelle Johnson| 21|\n|       Joey Abreu| 22|\n|   Preston Suarez| 22|\n|         Lee Dong| 24|\n|    Maa'iz al-Dia| 22|\n|   Maja Nicholson| 23|\n|     Sasha Jansen| 21|\n|Alexander Sherman| 20|\n|    Edgar Sanchez| 23|\n|     Kolbi Strunk| 21|\n|    Brittany Sath| 21|\n|     Meggan Smith| 21|\n|   Ericka Arreola| 23|\n|       David Pulc| 24|\n|      Kyle Luckey| 23|\n+-----------------+---+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import col\ndf.select(col('age'),col('name')).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"82e5f860-fff9-48ac-92a0-5c0bdf3e5c41","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+-----------------+\n|age|             name|\n+---+-----------------+\n| 22|        Kiana Lor|\n| 22|   Joshua Lonaker|\n| 22|    Dakota Blanco|\n| 20|  Natasha Yarusso|\n| 21|   Brooke Cazares|\n| 21| Rochelle Johnson|\n| 22|       Joey Abreu|\n| 22|   Preston Suarez|\n| 24|         Lee Dong|\n| 22|    Maa'iz al-Dia|\n| 23|   Maja Nicholson|\n| 21|     Sasha Jansen|\n| 20|Alexander Sherman|\n| 23|    Edgar Sanchez|\n| 21|     Kolbi Strunk|\n| 21|    Brittany Sath|\n| 21|     Meggan Smith|\n| 23|   Ericka Arreola|\n| 24|       David Pulc|\n| 23|      Kyle Luckey|\n+---+-----------------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["df.columns"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"49ef5d3e-f9dd-4335-80e3-39fe09906a0a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[15]: ['age', 'gender', 'name', 'course', 'roll', 'marks', 'email']"]}],"execution_count":0},{"cell_type":"code","source":["#access all columns in diff way\ndf.select(df.columns[3:6]).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"8d12d8fc-31b3-4bb8-9614-403d0d2123bb","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+--------------+----+-----+\n|        course|roll|marks|\n+--------------+----+-----+\n|    Data Enggg| 101|  100|\n|   Cloud Admin| 102|   99|\n|        DevOps| 103|   65|\n|     FullStack| 104|   78|\n|         MLOps| 105|   98|\n|data Scientist| 106|   54|\n|      FrontEnd| 107|   63|\n|       Backend| 108|   48|\n|         UI/UX| 109|   87|\n|           SRE| 110|   69|\n|  Network engg| 111|   57|\n| Security Engg| 112|   99|\n|    Data Enggg| 113|   65|\n|   Cloud Admin| 114|   78|\n|        DevOps| 115|   98|\n|     FullStack| 116|   54|\n|         MLOps| 117|   63|\n|data Scientist| 118|   48|\n|      FrontEnd| 119|   87|\n|       Backend| 120|   69|\n+--------------+----+-----+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["df.select('name',df.age,col('gender')).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"ca17db20-e5c0-4cfb-8486-b360e0a1b2b0","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-----------------+---+------+\n|             name|age|gender|\n+-----------------+---+------+\n|        Kiana Lor| 22|     F|\n|   Joshua Lonaker| 22|     M|\n|    Dakota Blanco| 22|     F|\n|  Natasha Yarusso| 20|     F|\n|   Brooke Cazares| 21|     F|\n| Rochelle Johnson| 21|     F|\n|       Joey Abreu| 22|     M|\n|   Preston Suarez| 22|     M|\n|         Lee Dong| 24|     F|\n|    Maa'iz al-Dia| 22|     M|\n|   Maja Nicholson| 23|     F|\n|     Sasha Jansen| 21|     F|\n|Alexander Sherman| 20|     M|\n|    Edgar Sanchez| 23|     M|\n|     Kolbi Strunk| 21|     M|\n|    Brittany Sath| 21|     F|\n|     Meggan Smith| 21|     F|\n|   Ericka Arreola| 23| other|\n|       David Pulc| 24|     M|\n|      Kyle Luckey| 23|     M|\n+-----------------+---+------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#withColumn(): this function used to manipulate column data plus chnage column data type\ndf = df.withColumn('roll',col('roll').cast('string'))\ndf.show()\ndf.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"ba7fa2b9-62b3-442a-9a0b-a6a659ab65d5","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+------+-----------------+--------------+----+-----+--------------------+\n|age|gender|             name|        course|roll|marks|               email|\n+---+------+-----------------+--------------+----+-----+--------------------+\n| 22|     F|        Kiana Lor|    Data Enggg| 101|  100|  KianaLor@gmail.com|\n| 22|     M|   Joshua Lonaker|   Cloud Admin| 102|   99|JoshuaLonaker@gma...|\n| 22|     F|    Dakota Blanco|        DevOps| 103|   65|DakotaBlanco@gmai...|\n| 20|     F|  Natasha Yarusso|     FullStack| 104|   78|NatashaYarusso@gm...|\n| 21|     F|   Brooke Cazares|         MLOps| 105|   98|BrookeCazares@gma...|\n| 21|     F| Rochelle Johnson|data Scientist| 106|   54|RochelleJohnson@g...|\n| 22|     M|       Joey Abreu|      FrontEnd| 107|   63| JoeyAbreu@gmail.com|\n| 22|     M|   Preston Suarez|       Backend| 108|   48|PrestonSuarez@gma...|\n| 24|     F|         Lee Dong|         UI/UX| 109|   87|   LeeDong@gmail.com|\n| 22|     M|    Maa'iz al-Dia|           SRE| 110|   69|Maa'izal-Dia@gmai...|\n| 23|     F|   Maja Nicholson|  Network engg| 111|   57|MajaNicholson@gma...|\n| 21|     F|     Sasha Jansen| Security Engg| 112|   99|SashaJansen@gmail...|\n| 20|     M|Alexander Sherman|    Data Enggg| 113|   65|AlexanderSherman@...|\n| 23|     M|    Edgar Sanchez|   Cloud Admin| 114|   78|EdgarSanchez@gmai...|\n| 21|     M|     Kolbi Strunk|        DevOps| 115|   98|KolbiStrunk@gmail...|\n| 21|     F|    Brittany Sath|     FullStack| 116|   54|BrittanySath@gmai...|\n| 21|     F|     Meggan Smith|         MLOps| 117|   63|MegganSmith@gmail...|\n| 23| other|   Ericka Arreola|data Scientist| 118|   48|ErickaArreola@gma...|\n| 24|     M|       David Pulc|      FrontEnd| 119|   87| DavidPulc@gmail.com|\n| 23|     M|      Kyle Luckey|       Backend| 120|   69|KyleLuckey@gmail.com|\n+---+------+-----------------+--------------+----+-----+--------------------+\nonly showing top 20 rows\n\nroot\n |-- age: integer (nullable = true)\n |-- gender: string (nullable = true)\n |-- name: string (nullable = true)\n |-- course: string (nullable = true)\n |-- roll: string (nullable = true)\n |-- marks: integer (nullable = true)\n |-- email: string (nullable = true)\n\n"]}],"execution_count":0},{"cell_type":"code","source":["              #new col name,col(col to be manipulated)\ndf.withColumn('marks',col('marks') + 10).show()    "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"4332b3a8-a66b-431e-ba77-e83f3ff65dcd","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+------+-----------------+--------------+----+-----+--------------------+\n|age|gender|             name|        course|roll|marks|               email|\n+---+------+-----------------+--------------+----+-----+--------------------+\n| 22|     F|        Kiana Lor|    Data Enggg| 101|  110|  KianaLor@gmail.com|\n| 22|     M|   Joshua Lonaker|   Cloud Admin| 102|  109|JoshuaLonaker@gma...|\n| 22|     F|    Dakota Blanco|        DevOps| 103|   75|DakotaBlanco@gmai...|\n| 20|     F|  Natasha Yarusso|     FullStack| 104|   88|NatashaYarusso@gm...|\n| 21|     F|   Brooke Cazares|         MLOps| 105|  108|BrookeCazares@gma...|\n| 21|     F| Rochelle Johnson|data Scientist| 106|   64|RochelleJohnson@g...|\n| 22|     M|       Joey Abreu|      FrontEnd| 107|   73| JoeyAbreu@gmail.com|\n| 22|     M|   Preston Suarez|       Backend| 108|   58|PrestonSuarez@gma...|\n| 24|     F|         Lee Dong|         UI/UX| 109|   97|   LeeDong@gmail.com|\n| 22|     M|    Maa'iz al-Dia|           SRE| 110|   79|Maa'izal-Dia@gmai...|\n| 23|     F|   Maja Nicholson|  Network engg| 111|   67|MajaNicholson@gma...|\n| 21|     F|     Sasha Jansen| Security Engg| 112|  109|SashaJansen@gmail...|\n| 20|     M|Alexander Sherman|    Data Enggg| 113|   75|AlexanderSherman@...|\n| 23|     M|    Edgar Sanchez|   Cloud Admin| 114|   88|EdgarSanchez@gmai...|\n| 21|     M|     Kolbi Strunk|        DevOps| 115|  108|KolbiStrunk@gmail...|\n| 21|     F|    Brittany Sath|     FullStack| 116|   64|BrittanySath@gmai...|\n| 21|     F|     Meggan Smith|         MLOps| 117|   73|MegganSmith@gmail...|\n| 23| other|   Ericka Arreola|data Scientist| 118|   58|ErickaArreola@gma...|\n| 24|     M|       David Pulc|      FrontEnd| 119|   97| DavidPulc@gmail.com|\n| 23|     M|      Kyle Luckey|       Backend| 120|   79|KyleLuckey@gmail.com|\n+---+------+-----------------+--------------+----+-----+--------------------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import lit\ndf1 = df.withColumn('Country',lit('India'))    #lit() function used to provide string to each row in provided column. If we give existing column then it will update existing column with new string values and if not then it will create new clumn with defauklt values provided in lit()\ndf1.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"43ee594d-d91d-485c-933e-e7d0ee9a3031","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+------+-----------------+--------------+----+-----+--------------------+-------+\n|age|gender|             name|        course|roll|marks|               email|Country|\n+---+------+-----------------+--------------+----+-----+--------------------+-------+\n| 22|     F|        Kiana Lor|    Data Enggg| 101|  100|  KianaLor@gmail.com|  India|\n| 22|     M|   Joshua Lonaker|   Cloud Admin| 102|   99|JoshuaLonaker@gma...|  India|\n| 22|     F|    Dakota Blanco|        DevOps| 103|   65|DakotaBlanco@gmai...|  India|\n| 20|     F|  Natasha Yarusso|     FullStack| 104|   78|NatashaYarusso@gm...|  India|\n| 21|     F|   Brooke Cazares|         MLOps| 105|   98|BrookeCazares@gma...|  India|\n| 21|     F| Rochelle Johnson|data Scientist| 106|   54|RochelleJohnson@g...|  India|\n| 22|     M|       Joey Abreu|      FrontEnd| 107|   63| JoeyAbreu@gmail.com|  India|\n| 22|     M|   Preston Suarez|       Backend| 108|   48|PrestonSuarez@gma...|  India|\n| 24|     F|         Lee Dong|         UI/UX| 109|   87|   LeeDong@gmail.com|  India|\n| 22|     M|    Maa'iz al-Dia|           SRE| 110|   69|Maa'izal-Dia@gmai...|  India|\n| 23|     F|   Maja Nicholson|  Network engg| 111|   57|MajaNicholson@gma...|  India|\n| 21|     F|     Sasha Jansen| Security Engg| 112|   99|SashaJansen@gmail...|  India|\n| 20|     M|Alexander Sherman|    Data Enggg| 113|   65|AlexanderSherman@...|  India|\n| 23|     M|    Edgar Sanchez|   Cloud Admin| 114|   78|EdgarSanchez@gmai...|  India|\n| 21|     M|     Kolbi Strunk|        DevOps| 115|   98|KolbiStrunk@gmail...|  India|\n| 21|     F|    Brittany Sath|     FullStack| 116|   54|BrittanySath@gmai...|  India|\n| 21|     F|     Meggan Smith|         MLOps| 117|   63|MegganSmith@gmail...|  India|\n| 23| other|   Ericka Arreola|data Scientist| 118|   48|ErickaArreola@gma...|  India|\n| 24|     M|       David Pulc|      FrontEnd| 119|   87| DavidPulc@gmail.com|  India|\n| 23|     M|      Kyle Luckey|       Backend| 120|   69|KyleLuckey@gmail.com|  India|\n+---+------+-----------------+--------------+----+-----+--------------------+-------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["# renaming column permanently with withColumnRenamed() or use alias() to rename temp\ndf.withColumnRenamed('name','Full Name').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"b41f03ac-6357-456b-8d53-0a91deace0fb","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+------+-----------------+--------------+----+-----+--------------------+\n|age|gender|        Full Name|        course|roll|marks|               email|\n+---+------+-----------------+--------------+----+-----+--------------------+\n| 22|     F|        Kiana Lor|    Data Enggg| 101|  100|  KianaLor@gmail.com|\n| 22|     M|   Joshua Lonaker|   Cloud Admin| 102|   99|JoshuaLonaker@gma...|\n| 22|     F|    Dakota Blanco|        DevOps| 103|   65|DakotaBlanco@gmai...|\n| 20|     F|  Natasha Yarusso|     FullStack| 104|   78|NatashaYarusso@gm...|\n| 21|     F|   Brooke Cazares|         MLOps| 105|   98|BrookeCazares@gma...|\n| 21|     F| Rochelle Johnson|data Scientist| 106|   54|RochelleJohnson@g...|\n| 22|     M|       Joey Abreu|      FrontEnd| 107|   63| JoeyAbreu@gmail.com|\n| 22|     M|   Preston Suarez|       Backend| 108|   48|PrestonSuarez@gma...|\n| 24|     F|         Lee Dong|         UI/UX| 109|   87|   LeeDong@gmail.com|\n| 22|     M|    Maa'iz al-Dia|           SRE| 110|   69|Maa'izal-Dia@gmai...|\n| 23|     F|   Maja Nicholson|  Network engg| 111|   57|MajaNicholson@gma...|\n| 21|     F|     Sasha Jansen| Security Engg| 112|   99|SashaJansen@gmail...|\n| 20|     M|Alexander Sherman|    Data Enggg| 113|   65|AlexanderSherman@...|\n| 23|     M|    Edgar Sanchez|   Cloud Admin| 114|   78|EdgarSanchez@gmai...|\n| 21|     M|     Kolbi Strunk|        DevOps| 115|   98|KolbiStrunk@gmail...|\n| 21|     F|    Brittany Sath|     FullStack| 116|   54|BrittanySath@gmai...|\n| 21|     F|     Meggan Smith|         MLOps| 117|   63|MegganSmith@gmail...|\n| 23| other|   Ericka Arreola|data Scientist| 118|   48|ErickaArreola@gma...|\n| 24|     M|       David Pulc|      FrontEnd| 119|   87| DavidPulc@gmail.com|\n| 23|     M|      Kyle Luckey|       Backend| 120|   69|KyleLuckey@gmail.com|\n+---+------+-----------------+--------------+----+-----+--------------------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["df.select(col('name').alias('Full Name')).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"2434dbc5-7faf-4b80-a3ba-8ed2896aaba1","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-----------------+\n|        Full Name|\n+-----------------+\n|        Kiana Lor|\n|   Joshua Lonaker|\n|    Dakota Blanco|\n|  Natasha Yarusso|\n|   Brooke Cazares|\n| Rochelle Johnson|\n|       Joey Abreu|\n|   Preston Suarez|\n|         Lee Dong|\n|    Maa'iz al-Dia|\n|   Maja Nicholson|\n|     Sasha Jansen|\n|Alexander Sherman|\n|    Edgar Sanchez|\n|     Kolbi Strunk|\n|    Brittany Sath|\n|     Meggan Smith|\n|   Ericka Arreola|\n|       David Pulc|\n|      Kyle Luckey|\n+-----------------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#conditional functions: where or filter, isin(),startswith(),endswith(),contains(),like()\n# df.filter(col('course') == 'DevOps').show()\ndf.filter(df.course.isin('DevOps','SRE')).show()\ndf.filter(df.course.startswith('D')).show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"c9faffc4-17a2-42d3-b4cb-4daf66d9e552","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+------+-------------------+------+----+-----+--------------------+\n|age|gender|               name|course|roll|marks|               email|\n+---+------+-------------------+------+----+-----+--------------------+\n| 22|     F|      Dakota Blanco|DevOps| 103|   65|DakotaBlanco@gmai...|\n| 22|     M|      Maa'iz al-Dia|   SRE| 110|   69|Maa'izal-Dia@gmai...|\n| 21|     M|       Kolbi Strunk|DevOps| 115|   98|KolbiStrunk@gmail...|\n| 20|     M|        David Weber|   SRE| 122|   55|DavidWeber@gmail.com|\n| 22|     F|     Angela Harding|DevOps| 127|   88|AngelaHarding@gma...|\n| 21|     M|         Sean Rozga|   SRE| 134|   48| SeanRozga@gmail.com|\n| 24|     M|    Joshua Galloway|DevOps| 139|   44|JoshuaGallowa@gma...|\n| 23|     F|    Britany Stevens|   SRE| 146|   45|BritanyStevens@gm...|\n| 23|     M|         Issac Mata|DevOps| 151|   63| IssacMata@gmail.com|\n| 22|     F|       Amanda Tatum|   SRE| 158|   78|AmandaTatum@gmail...|\n| 23|     M|      Donald Nevins|DevOps| 163|   87|DonaldNevins@gmai...|\n| 24|     F|Allison Brink-Lomme|   SRE| 170|   88|AllisonBrink-Lomm...|\n| 21|     F|      Taylor Elstun|DevOps| 175|   78|TaylorElstun@gmai...|\n| 22|     M|   Casey Vanden Bos|   SRE| 182|  100|CaseyVandenBos@gm...|\n| 21|     M|       Myles Vaught|DevOps| 187|   54|MylesVaught@gmail...|\n| 22|     F|       Hailey Malle|   SRE| 194|   65|HaileyMalle@gmail...|\n| 20|     M|  Jason Hundsdorfer|DevOps| 199|   48|JasonHundsdorfer@...|\n| 23|     M|       Duncan Kruse|DevOps| 204|   44|DuncanKruse@gmail...|\n| 23|     M|   Riley Mcloughlin|DevOps| 209|   99|RileyMcloughlin@g...|\n| 21|     F|  Brandilyn Collins|   SRE| 215|   48|BrandilynCollins@...|\n+---+------+-------------------+------+----+-----+--------------------+\nonly showing top 20 rows\n\n+---+------+--------------------+----------+----+-----+--------------------+\n|age|gender|                name|    course|roll|marks|               email|\n+---+------+--------------------+----------+----+-----+--------------------+\n| 22|     F|           Kiana Lor|Data Enggg| 101|  100|  KianaLor@gmail.com|\n| 22|     F|       Dakota Blanco|    DevOps| 103|   65|DakotaBlanco@gmai...|\n| 20|     M|   Alexander Sherman|Data Enggg| 113|   65|AlexanderSherman@...|\n| 21|     M|        Kolbi Strunk|    DevOps| 115|   98|KolbiStrunk@gmail...|\n| 23|     M|         Sila Nguyen|Data Enggg| 125|   77|SilaNguyen@gmail.com|\n| 22|     F|      Angela Harding|    DevOps| 127|   88|AngelaHarding@gma...|\n| 22|     M|       Daniel Garcia|Data Enggg| 137|   57|DanielGarciav@gma...|\n| 24|     M|     Joshua Galloway|    DevOps| 139|   44|JoshuaGallowa@gma...|\n| 23|     M|      Sidney Beavers|Data Enggg| 149|   98|SidneyBeavers@gma...|\n| 23|     M|          Issac Mata|    DevOps| 151|   63| IssacMata@gmail.com|\n| 20|     F|       Katelyn Sharp|Data Enggg| 161|   63|KatelynSharp@gmai...|\n| 23|     M|       Donald Nevins|    DevOps| 163|   87|DonaldNevins@gmai...|\n| 21|     F|       Fikra al-Mina|Data Enggg| 173|   45|Fikraal-Mina@gmai...|\n| 21|     F|       Taylor Elstun|    DevOps| 175|   78|TaylorElstun@gmai...|\n| 23|     F|Harper Wheeler-Ma...|Data Enggg| 185|   78|HarperWheeler-Mar...|\n| 21|     M|        Myles Vaught|    DevOps| 187|   54|MylesVaught@gmail...|\n| 23|     M|      Mateo Cisneros|Data Enggg| 197|   54|MateoCisneros@gma...|\n| 20|     M|   Jason Hundsdorfer|    DevOps| 199|   48|JasonHundsdorfer@...|\n| 22|     M| Mamdooh el-Moustafa|Data Enggg| 202|   57|Mamdoohel-Moustaf...|\n| 23|     M|        Duncan Kruse|    DevOps| 204|   44|DuncanKruse@gmail...|\n+---+------+--------------------+----------+----+-----+--------------------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#assignment:\n#1. create new column as total marks and letr the total marks be 120\n#2. create new column as average to calculate the average marks of student (marks/toal marks)*100\n#3. Filter out all those students who got >80% marks in DevOps course and save it as new data frame\n#print the names and marks of all students from the above df."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"7e41d745-9fb0-4aae-815c-144899932617","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#1. create new column as total marks and letr the total marks be 120\nfrom pyspark.sql.functions import lit, col\ntot_marksdf = df.withColumn('Total_Marks',lit(120))\ntot_marksdf.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"8084aeea-1e7a-40e3-9607-c23ca3de0d68","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+------+-----------------+--------------+----+-----+--------------------+-----------+\n|age|gender|             name|        course|roll|marks|               email|Total_Marks|\n+---+------+-----------------+--------------+----+-----+--------------------+-----------+\n| 22|     F|        Kiana Lor|    Data Enggg| 101|  100|  KianaLor@gmail.com|        120|\n| 22|     M|   Joshua Lonaker|   Cloud Admin| 102|   99|JoshuaLonaker@gma...|        120|\n| 22|     F|    Dakota Blanco|        DevOps| 103|   65|DakotaBlanco@gmai...|        120|\n| 20|     F|  Natasha Yarusso|     FullStack| 104|   78|NatashaYarusso@gm...|        120|\n| 21|     F|   Brooke Cazares|         MLOps| 105|   98|BrookeCazares@gma...|        120|\n| 21|     F| Rochelle Johnson|data Scientist| 106|   54|RochelleJohnson@g...|        120|\n| 22|     M|       Joey Abreu|      FrontEnd| 107|   63| JoeyAbreu@gmail.com|        120|\n| 22|     M|   Preston Suarez|       Backend| 108|   48|PrestonSuarez@gma...|        120|\n| 24|     F|         Lee Dong|         UI/UX| 109|   87|   LeeDong@gmail.com|        120|\n| 22|     M|    Maa'iz al-Dia|           SRE| 110|   69|Maa'izal-Dia@gmai...|        120|\n| 23|     F|   Maja Nicholson|  Network engg| 111|   57|MajaNicholson@gma...|        120|\n| 21|     F|     Sasha Jansen| Security Engg| 112|   99|SashaJansen@gmail...|        120|\n| 20|     M|Alexander Sherman|    Data Enggg| 113|   65|AlexanderSherman@...|        120|\n| 23|     M|    Edgar Sanchez|   Cloud Admin| 114|   78|EdgarSanchez@gmai...|        120|\n| 21|     M|     Kolbi Strunk|        DevOps| 115|   98|KolbiStrunk@gmail...|        120|\n| 21|     F|    Brittany Sath|     FullStack| 116|   54|BrittanySath@gmai...|        120|\n| 21|     F|     Meggan Smith|         MLOps| 117|   63|MegganSmith@gmail...|        120|\n| 23| other|   Ericka Arreola|data Scientist| 118|   48|ErickaArreola@gma...|        120|\n| 24|     M|       David Pulc|      FrontEnd| 119|   87| DavidPulc@gmail.com|        120|\n| 23|     M|      Kyle Luckey|       Backend| 120|   69|KyleLuckey@gmail.com|        120|\n+---+------+-----------------+--------------+----+-----+--------------------+-----------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#2. create new column as average to calculate the average marks of student (marks/toal marks)*100\nperdf = tot_marksdf.withColumn('Average',lit(col('marks')/col('Total_Marks'))*100)\nperdf.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"be8613a8-459d-4fe1-89f7-8420f8b3c2be","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+------+-----------------+--------------+----+-----+--------------------+-----------+------------------+\n|age|gender|             name|        course|roll|marks|               email|Total_Marks|           Average|\n+---+------+-----------------+--------------+----+-----+--------------------+-----------+------------------+\n| 22|     F|        Kiana Lor|    Data Enggg| 101|  100|  KianaLor@gmail.com|        120| 83.33333333333334|\n| 22|     M|   Joshua Lonaker|   Cloud Admin| 102|   99|JoshuaLonaker@gma...|        120|              82.5|\n| 22|     F|    Dakota Blanco|        DevOps| 103|   65|DakotaBlanco@gmai...|        120|54.166666666666664|\n| 20|     F|  Natasha Yarusso|     FullStack| 104|   78|NatashaYarusso@gm...|        120|              65.0|\n| 21|     F|   Brooke Cazares|         MLOps| 105|   98|BrookeCazares@gma...|        120| 81.66666666666667|\n| 21|     F| Rochelle Johnson|data Scientist| 106|   54|RochelleJohnson@g...|        120|              45.0|\n| 22|     M|       Joey Abreu|      FrontEnd| 107|   63| JoeyAbreu@gmail.com|        120|              52.5|\n| 22|     M|   Preston Suarez|       Backend| 108|   48|PrestonSuarez@gma...|        120|              40.0|\n| 24|     F|         Lee Dong|         UI/UX| 109|   87|   LeeDong@gmail.com|        120|              72.5|\n| 22|     M|    Maa'iz al-Dia|           SRE| 110|   69|Maa'izal-Dia@gmai...|        120| 57.49999999999999|\n| 23|     F|   Maja Nicholson|  Network engg| 111|   57|MajaNicholson@gma...|        120|              47.5|\n| 21|     F|     Sasha Jansen| Security Engg| 112|   99|SashaJansen@gmail...|        120|              82.5|\n| 20|     M|Alexander Sherman|    Data Enggg| 113|   65|AlexanderSherman@...|        120|54.166666666666664|\n| 23|     M|    Edgar Sanchez|   Cloud Admin| 114|   78|EdgarSanchez@gmai...|        120|              65.0|\n| 21|     M|     Kolbi Strunk|        DevOps| 115|   98|KolbiStrunk@gmail...|        120| 81.66666666666667|\n| 21|     F|    Brittany Sath|     FullStack| 116|   54|BrittanySath@gmai...|        120|              45.0|\n| 21|     F|     Meggan Smith|         MLOps| 117|   63|MegganSmith@gmail...|        120|              52.5|\n| 23| other|   Ericka Arreola|data Scientist| 118|   48|ErickaArreola@gma...|        120|              40.0|\n| 24|     M|       David Pulc|      FrontEnd| 119|   87| DavidPulc@gmail.com|        120|              72.5|\n| 23|     M|      Kyle Luckey|       Backend| 120|   69|KyleLuckey@gmail.com|        120| 57.49999999999999|\n+---+------+-----------------+--------------+----+-----+--------------------+-----------+------------------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#3. Filter out all those students who got >80% marks in DevOps course and save it as new data frame\neightydf = perdf.filter((col('course') == 'DevOps') & (col('Average') > 80))\neightydf.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"7cf77af6-9891-4222-b71d-4b21fd7ab11c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+------+----------------+------+----+-----+--------------------+-----------+-----------------+\n|age|gender|            name|course|roll|marks|               email|Total_Marks|          Average|\n+---+------+----------------+------+----+-----+--------------------+-----------+-----------------+\n| 21|     M|    Kolbi Strunk|DevOps| 115|   98|KolbiStrunk@gmail...|        120|81.66666666666667|\n| 23|     M|Riley Mcloughlin|DevOps| 209|   99|RileyMcloughlin@g...|        120|             82.5|\n+---+------+----------------+------+----+-----+--------------------+-----------+-----------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#count,distinct,dropDuplicates() - > it will drop all duplicate records \ndf.count()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"1501dc51-80a1-417a-9cdd-1ce3b39fb535","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[28]: 143"]}],"execution_count":0},{"cell_type":"code","source":["df.select('gender').distinct().show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"f2f3a2c6-4717-425d-a100-5640bb803f66","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+------+\n|gender|\n+------+\n|     F|\n|     M|\n| other|\n+------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["df.dropDuplicates(['gender','course']).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"439a04b4-58a9-46b0-a652-b283feeec25d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+------+-----------------+--------------+----+-----+--------------------+\n|age|gender|             name|        course|roll|marks|               email|\n+---+------+-----------------+--------------+----+-----+--------------------+\n| 22|     F|   Lauren Klocker|       Backend| 132|   54|LaurenKlocker@gma...|\n| 22|     F|   Samantha Hicks|   Cloud Admin| 126|   77|SamanthaHicks@gma...|\n| 22|     F|        Kiana Lor|    Data Enggg| 101|  100|  KianaLor@gmail.com|\n| 22|     F|    Dakota Blanco|        DevOps| 103|   65|DakotaBlanco@gmai...|\n| 22|     F|     Dakota Wirth|      FrontEnd| 131|   37|DakotaWirth@gmail...|\n| 20|     F|  Natasha Yarusso|     FullStack| 104|   78|NatashaYarusso@gm...|\n| 21|     F|   Brooke Cazares|         MLOps| 105|   98|BrookeCazares@gma...|\n| 23|     F|   Maja Nicholson|  Network engg| 111|   57|MajaNicholson@gma...|\n| 23|     F|  Britany Stevens|           SRE| 146|   45|BritanyStevens@gm...|\n| 21|     F|     Sasha Jansen| Security Engg| 112|   99|SashaJansen@gmail...|\n| 24|     F|         Lee Dong|         UI/UX| 109|   87|   LeeDong@gmail.com|\n| 21|     F| Rochelle Johnson|data Scientist| 106|   54|RochelleJohnson@g...|\n| 22|     M|   Preston Suarez|       Backend| 108|   48|PrestonSuarez@gma...|\n| 22|     M|   Joshua Lonaker|   Cloud Admin| 102|   99|JoshuaLonaker@gma...|\n| 20|     M|Alexander Sherman|    Data Enggg| 113|   65|AlexanderSherman@...|\n| 21|     M|     Kolbi Strunk|        DevOps| 115|   98|KolbiStrunk@gmail...|\n| 22|     M|       Joey Abreu|      FrontEnd| 107|   63| JoeyAbreu@gmail.com|\n| 21|     M|  Brandon Barbour|     FullStack| 128|   99|BrandonBarbour@gm...|\n| 21|     M|  Zachary Bradley|         MLOps| 153|   87|ZacharyBradley@gm...|\n| 23|     M|   Cody Vermeylen|  Network engg| 135|   87|CodyVermeylen@gma...|\n+---+------+-----------------+--------------+----+-----+--------------------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#write a code to show all unique rows of age,gender and course\ndf.dropDuplicates(['age','gender','course']).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"92fd665c-f476-4677-a93a-11e8cfb2b556","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+------+--------------------+--------------+----+-----+--------------------+\n|age|gender|                name|        course|roll|marks|               email|\n+---+------+--------------------+--------------+----+-----+--------------------+\n| 19|     F|        Faviola Soto|     FullStack| 241|   54|FaviolaSoto@gmail...|\n| 19|     F|        Shauna Sneed|         MLOps| 232|   63|ShaunaSneed@gmail...|\n| 20|     F|       Katelyn Sharp|    Data Enggg| 161|   63|KatelynSharp@gmai...|\n| 20|     F|     Natasha Yarusso|     FullStack| 104|   78|NatashaYarusso@gm...|\n| 20|     F|      Lindsey Freund|         MLOps| 189|   48|LindseyFreund@gma...|\n| 20|     F|      Savannah Clark|data Scientist| 190|   87|SavannahClark@gma...|\n| 20|     M|   Alexander Sherman|    Data Enggg| 113|   65|AlexanderSherman@...|\n| 20|     M|   Jason Hundsdorfer|        DevOps| 199|   48|JasonHundsdorfer@...|\n| 20|     M|          James Rice|     FullStack| 222|   77| JamesRice@gmail.com|\n| 20|     M|          Alan Trinh|  Network engg| 147|   37| AlanTrinh@gmail.com|\n| 20|     M|         David Weber|           SRE| 122|   55|DavidWeber@gmail.com|\n| 21|     F|       Fikra al-Mina|    Data Enggg| 173|   45|Fikraal-Mina@gmai...|\n| 21|     F|       Taylor Elstun|        DevOps| 175|   78|TaylorElstun@gmai...|\n| 21|     F|      Jesse Williams|      FrontEnd| 143|   88|JesseWilliams@gma...|\n| 21|     F|       Brittany Sath|     FullStack| 116|   54|BrittanySath@gmai...|\n| 21|     F|      Brooke Cazares|         MLOps| 105|   98|BrookeCazares@gma...|\n| 21|     F|Sheyenne Delgado-...|  Network engg| 171|   99|SheyenneDelgado-M...|\n| 21|     F|   Brandilyn Collins|           SRE| 215|   48|BrandilynCollins@...|\n| 21|     F|        Sasha Jansen| Security Engg| 112|   99|SashaJansen@gmail...|\n| 21|     F|    Rochelle Johnson|data Scientist| 106|   54|RochelleJohnson@g...|\n+---+------+--------------------+--------------+----+-----+--------------------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#sort() or orderBy(): used to sort the numbers in ascending or descending order.\n#sort() function works only on number data type.\ndf.sort(df.marks.desc()).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"968ae2d6-38ce-437f-ad6e-352712e62612","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+------+--------------------+-------------+----+-----+--------------------+\n|age|gender|                name|       course|roll|marks|               email|\n+---+------+--------------------+-------------+----+-----+--------------------+\n| 22|     F|           Kiana Lor|   Data Enggg| 101|  100|  KianaLor@gmail.com|\n| 22|     M|    Casey Vanden Bos|          SRE| 182|  100|CaseyVandenBos@gm...|\n| 22|     M|      Joshua Lonaker|  Cloud Admin| 102|   99|JoshuaLonaker@gma...|\n| 21|     F|        Sasha Jansen|Security Engg| 112|   99|SashaJansen@gmail...|\n| 21|     M|     Brandon Barbour|    FullStack| 128|   99|BrandonBarbour@gm...|\n| 22|     M|     Kenny Fukushima|      Backend| 144|   99|KennyFukushima@gm...|\n| 23|     F|    Georgia Williams|      Backend| 156|   99|GeorgiaWilliams@g...|\n| 21|     F|Sheyenne Delgado-...| Network engg| 171|   99|SheyenneDelgado-M...|\n| 23|     F|          Staci Maes| Network engg| 183|   99| StaciMaes@gmail.com|\n| 22|     F|    Airabella Koontz|        UI/UX| 193|   99|AirabellaKoontz@g...|\n| 23|     M|    Riley Mcloughlin|       DevOps| 209|   99|RileyMcloughlin@g...|\n| 21|     M|      Austin Harline|    FullStack| 225|   99|AustinHarline@gma...|\n| 23|     M|         Kevin Curry|    FullStack| 237|   99|KevinCurry@gmail.com|\n| 23|     M|      Sidney Beavers|   Data Enggg| 149|   98|SidneyBeavers@gma...|\n| 21|     M|        Kolbi Strunk|       DevOps| 115|   98|KolbiStrunk@gmail...|\n| 21|     F|      Brooke Cazares|        MLOps| 105|   98|BrookeCazares@gma...|\n| 20|     M|   Cameron Steinberg| Network engg| 159|   98|CameronSteinbergv...|\n| 21|     M|       Joseph Snider|    FullStack| 176|   98|JosephSnider@gmai...|\n| 22|     F|  Sherleen Saravanan|  Cloud Admin| 186|   98|SherleenSaravanan...|\n| 23|     F|     Danielle Nguyen|Security Engg| 196|   98|DanielleNguyen@gm...|\n+---+------+--------------------+-------------+----+-----+--------------------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["df.orderBy('course').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"b5a6cbd2-c24e-48c0-8518-c3944324b4ec","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+------+--------------------+-----------+----+-----+--------------------+\n|age|gender|                name|     course|roll|marks|               email|\n+---+------+--------------------+-----------+----+-----+--------------------+\n| 22|     M|     Kenny Fukushima|    Backend| 144|   99|KennyFukushima@gm...|\n| 22|     M|      Preston Suarez|    Backend| 108|   48|PrestonSuarez@gma...|\n| 23|     M|         Kyle Luckey|    Backend| 120|   69|KyleLuckey@gmail.com|\n| 22|     F|      Lauren Klocker|    Backend| 132|   54|LaurenKlocker@gma...|\n| 23|     F|    Georgia Williams|    Backend| 156|   99|GeorgiaWilliams@g...|\n| 23|     F|         Lindsey Job|    Backend| 168|   77|LindseyJob@gmail.com|\n| 23|     F|        Macie Nguyen|    Backend| 180|   87|MacieNguyen@gmail...|\n| 22|     F|      Daisha Schmidt|    Backend| 192|   57|DaishaSchmidt@gma...|\n| 23|     M|Christian Zambran...|    Backend| 213|   54|ChristianZambrano...|\n| 22|     F|        Marisa Ramey|    Backend| 218|   57|MarisaRamey@gmail...|\n| 22|     M|      Joshua Lonaker|Cloud Admin| 102|   99|JoshuaLonaker@gma...|\n| 23|     M|       Edgar Sanchez|Cloud Admin| 114|   78|EdgarSanchez@gmai...|\n| 22|     F|      Samantha Hicks|Cloud Admin| 126|   77|SamanthaHicks@gma...|\n| 22|     F|       Katrina Saito|Cloud Admin| 138|   55|KatrinaSaitov@gma...|\n| 22|     F|      Miriam Aguilar|Cloud Admin| 150|   54|MiriamAguilar@gma...|\n| 21|     M|        Colin Lemont|Cloud Admin| 162|   48|ColinLemont@gmail...|\n| 22|     F|Aurelia Davis Ingham|Cloud Admin| 174|   37|AureliaDavisIngha...|\n| 22|     F|  Sherleen Saravanan|Cloud Admin| 186|   98|SherleenSaravanan...|\n| 24|     M|       William Pablo|Cloud Admin| 198|   63|WilliamPablo@gmai...|\n| 24|     F|      Lindsey Carter|Cloud Admin| 203|   55|LindseyCarter@gma...|\n+---+------+--------------------+-----------+----+-----+--------------------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#assignments: use OfficeData.csv to read \n#1. create a DF, sorted on bonus in ascending order and show it.\n#2. Create a DF, sorted on age and salary in descending and ascending order respectively and show it.\n#3. Create a DF, sorted on age,bonus and salary in descending, descending and ascending order respectively and show it."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"740190d5-8f23-466d-932b-67cde9324f33","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df = spark.read.options(header='True',inferSchema='True').csv('/FileStore/tables/OfficeData.csv')\ndf.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"220a4ebf-fa6d-4d12-a021-42c0cf6760d3","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|        James|     Sales|   NY| 90000| 34|10000|\n|      Michael|     Sales|   NY| 86000| 56|20000|\n|       Robert|     Sales|   CA| 81000| 30|23000|\n|        Maria|   Finance|   CA| 90000| 24|23000|\n|        Raman|   Finance|   CA| 99000| 40|24000|\n|        Scott|   Finance|   NY| 83000| 36|19000|\n|          Jen|   Finance|   NY| 79000| 53|15000|\n|         Jeff| Marketing|   CA| 80000| 25|18000|\n|        Kumar| Marketing|   NY| 91000| 50|21000|\n+-------------+----------+-----+------+---+-----+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#1. create a DF, sorted on bonus in ascending order and show it.\ndf1 = df.sort(df.bonus)\ndf1.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"6172b632-dbbd-425e-ab3f-78652de99be5","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|        James|     Sales|   NY| 90000| 34|10000|\n|          Jen|   Finance|   NY| 79000| 53|15000|\n|         Jeff| Marketing|   CA| 80000| 25|18000|\n|        Scott|   Finance|   NY| 83000| 36|19000|\n|      Michael|     Sales|   NY| 86000| 56|20000|\n|        Kumar| Marketing|   NY| 91000| 50|21000|\n|       Robert|     Sales|   CA| 81000| 30|23000|\n|        Maria|   Finance|   CA| 90000| 24|23000|\n|        Raman|   Finance|   CA| 99000| 40|24000|\n+-------------+----------+-----+------+---+-----+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#2. Create a DF, sorted on age and salary in descending and ascending order respectively and show it.\ndf2 = df.orderBy((col('age').desc()),df.salary)\ndf2.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"a4cf36d4-19d5-4863-b68c-235144451729","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|      Michael|     Sales|   NY| 86000| 56|20000|\n|          Jen|   Finance|   NY| 79000| 53|15000|\n|        Kumar| Marketing|   NY| 91000| 50|21000|\n|        Raman|   Finance|   CA| 99000| 40|24000|\n|        Scott|   Finance|   NY| 83000| 36|19000|\n|        James|     Sales|   NY| 90000| 34|10000|\n|       Robert|     Sales|   CA| 81000| 30|23000|\n|         Jeff| Marketing|   CA| 80000| 25|18000|\n|        Maria|   Finance|   CA| 90000| 24|23000|\n+-------------+----------+-----+------+---+-----+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#3. Create a DF, sorted on age,bonus and salary in descending, descending and ascending order respectively and show it.\ndf3 = df.sort(df.age.desc(),df.bonus.desc(),df.salary)\ndf3.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"508522a7-0e54-45c2-81e3-2b7b478d3aa4","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|      Michael|     Sales|   NY| 86000| 56|20000|\n|          Jen|   Finance|   NY| 79000| 53|15000|\n|        Kumar| Marketing|   NY| 91000| 50|21000|\n|        Raman|   Finance|   CA| 99000| 40|24000|\n|        Scott|   Finance|   NY| 83000| 36|19000|\n|        James|     Sales|   NY| 90000| 34|10000|\n|       Robert|     Sales|   CA| 81000| 30|23000|\n|         Jeff| Marketing|   CA| 80000| 25|18000|\n|        Maria|   Finance|   CA| 90000| 24|23000|\n+-------------+----------+-----+------+---+-----+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#groupBy(): this function always works with aggregation function. \ndf = spark.read.options(header='true',inferSchema='true').csv('/FileStore/tables/StudentData.csv')\ndf.groupBy('gender').avg('age').show()\ndf.groupBy('course').max('marks').show()\ndf.groupBy('course').min('marks').show()\ndf.groupBy('course').sum('marks').show()\ndf.groupBy('course').count().show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"31b1ce64-bcf3-4a3f-91d3-7ab781c405e8","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+------+------------------+\n|gender|          avg(age)|\n+------+------------------+\n|Female|28.489021956087825|\n|  Male| 28.52304609218437|\n+------+------------------+\n\n+------+----------+\n|course|max(marks)|\n+------+----------+\n|    PF|        99|\n|    DB|        98|\n|   MVC|        99|\n|   DSA|        99|\n| Cloud|        99|\n|   OOP|        99|\n+------+----------+\n\n+------+----------+\n|course|min(marks)|\n+------+----------+\n|    PF|        20|\n|    DB|        20|\n|   MVC|        22|\n|   DSA|        20|\n| Cloud|        20|\n|   OOP|        20|\n+------+----------+\n\n+------+----------+\n|course|sum(marks)|\n+------+----------+\n|    PF|      9933|\n|    DB|      9270|\n|   MVC|      9585|\n|   DSA|     10950|\n| Cloud|     11443|\n|   OOP|      8916|\n+------+----------+\n\n+------+-----+\n|course|count|\n+------+-----+\n|    PF|  166|\n|    DB|  157|\n|   MVC|  157|\n|   DSA|  176|\n| Cloud|  192|\n|   OOP|  152|\n+------+-----+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#groupBy with multiple columns and multiple aggregated functions\nfrom pyspark.sql.functions import min,max,sum,count,avg,mean\ndf.groupBy('course','gender').agg(count('*').alias('Total_enrollment'),sum('marks').alias('Total_Marks'),min('marks').alias('Min Marks'),max('marks').alias('Max marks')).orderBy('course').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"7bea7b9e-c293-4789-9263-b1587cd80601","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+------+------+----------------+-----------+---------+---------+\n|course|gender|Total_enrollment|Total_Marks|Min Marks|Max marks|\n+------+------+----------------+-----------+---------+---------+\n| Cloud|Female|             106|       6316|       20|       99|\n| Cloud|  Male|              86|       5127|       21|       97|\n|    DB|  Male|              82|       5073|       20|       98|\n|    DB|Female|              75|       4197|       20|       96|\n|   DSA|Female|              98|       6124|       20|       99|\n|   DSA|  Male|              78|       4826|       20|       99|\n|   MVC|  Male|              86|       5241|       22|       99|\n|   MVC|Female|              71|       4344|       22|       99|\n|   OOP|  Male|              70|       4234|       20|       99|\n|   OOP|Female|              82|       4682|       21|       99|\n|    PF|  Male|              97|       5960|       20|       99|\n|    PF|Female|              69|       3973|       20|       99|\n+------+------+----------------+-----------+---------+---------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#filter can be applied in 2 ways in groupBy(). 1st is before and 2nd is after groupBy(). But bth works the same way.\nfrom pyspark.sql.functions import min,max,sum,count,avg,mean\ndf.groupBy('course','gender').agg(count('*').alias('Total_enrollment'),sum('marks').alias('Total_Marks'),min('marks').alias('Min Marks'),max('marks').alias('Max marks')).orderBy('course').where(col('gender') != 'Male').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"82799625-ab14-4006-b526-6734d7bd500a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+------+------+----------------+-----------+---------+---------+\n|course|gender|Total_enrollment|Total_Marks|Min Marks|Max marks|\n+------+------+----------------+-----------+---------+---------+\n| Cloud|Female|             106|       6316|       20|       99|\n|    DB|Female|              75|       4197|       20|       96|\n|   DSA|Female|              98|       6124|       20|       99|\n|   MVC|Female|              71|       4344|       22|       99|\n|   OOP|Female|              82|       4682|       21|       99|\n|    PF|Female|              69|       3973|       20|       99|\n+------+------+----------------+-----------+---------+---------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#assignment: use Studentdata.csv\n#1. Display the total number of students enrolled in each course\n#2. Display the total number of male and females enrolled in each course\n#3. Display the total marks achived by each gender in each course\n#4. Display the min,max,avg marks achived in each course by same age group"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"d4242090-df60-4cf8-b68f-6cd191920d69","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#1. Display the total number of students enrolled in each course\ndf.groupBy('course').count().show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"ddfecb3c-a870-476c-a367-cba03152205c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+------+-----+\n|course|count|\n+------+-----+\n|    PF|  166|\n|    DB|  157|\n|   MVC|  157|\n|   DSA|  176|\n| Cloud|  192|\n|   OOP|  152|\n+------+-----+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#2. Display the total number of male and females enrolled in each course\ndf.groupBy('course','gender').count().show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"821012fc-419a-4c44-a872-1785e978da76","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+------+------+-----+\n|course|gender|count|\n+------+------+-----+\n|   OOP|  Male|   70|\n|    DB|  Male|   82|\n| Cloud|Female|  106|\n|   MVC|  Male|   86|\n|   DSA|Female|   98|\n|    PF|  Male|   97|\n|   MVC|Female|   71|\n| Cloud|  Male|   86|\n|    PF|Female|   69|\n|   DSA|  Male|   78|\n|    DB|Female|   75|\n|   OOP|Female|   82|\n+------+------+-----+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#3. Display the total marks achived by each gender in each course\ndf.groupBy('course','gender').sum('marks').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"7f85fe1b-9b1b-4ccd-8e27-27273089a65b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+------+------+----------+\n|course|gender|sum(marks)|\n+------+------+----------+\n|   OOP|  Male|      4234|\n|    DB|  Male|      5073|\n| Cloud|Female|      6316|\n|   MVC|  Male|      5241|\n|   DSA|Female|      6124|\n|    PF|  Male|      5960|\n|   MVC|Female|      4344|\n| Cloud|  Male|      5127|\n|    PF|Female|      3973|\n|   DSA|  Male|      4826|\n|    DB|Female|      4197|\n|   OOP|Female|      4682|\n+------+------+----------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#4. Display the min,max,avg marks achived in each course by same age group\ndf.groupBy('course','age').agg(min('marks').alias('Min_Marks'),max('marks').alias('Max Marks'),avg('marks').alias('Average Marks')).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"b25863d5-3718-4e49-8545-24ca4bdc44b4","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+------+---+---------+---------+------------------+\n|course|age|Min_Marks|Max Marks|     Average Marks|\n+------+---+---------+---------+------------------+\n|   MVC| 28|       23|       99| 60.44444444444444|\n|   MVC| 29|       22|       99| 61.56470588235294|\n| Cloud| 28|       20|       99|             58.08|\n|    PF| 29|       20|       99|56.275862068965516|\n|    PF| 28|       20|       98| 63.75949367088607|\n|   OOP| 29|       20|       99|59.729729729729726|\n|   DSA| 28|       20|       99|  64.6867469879518|\n| Cloud| 29|       21|       98|             61.25|\n|    DB| 28|       21|       98| 58.76829268292683|\n|   DSA| 29|       20|       99| 60.01075268817204|\n|   OOP| 28|       23|       99| 57.64102564102564|\n|    DB| 29|       20|       98|59.346666666666664|\n+------+---+---------+---------+------------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#assignment2: read worddata.text\n#1. calculate and show the count of each word in file\nfrom pyspark.sql.types import StructField,StructType,StringType\nschema = StructType([\n    StructField('words',StringType(),True)\n])\ndf = spark.read.options(delimiter='\\n').schema(schema=schema).csv('/FileStore/tables/WordData.txt')\ndf.groupBy('words').count().show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"b81a237b-ad17-45a2-9087-08553aebfc86","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+------+-----+\n| words|count|\n+------+-----+\n|   Mic|   10|\n| Chair|   15|\n|  Book|    5|\n|Laptop|    5|\n|   Bag|    5|\n|Mobile|    5|\n| Apple|   10|\n+------+-----+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#UDF: user defined functions: user programmable routine act on row.\nfrom pyspark.sql.functions import udf\nfrom pyspark.sql.types import IntegerType\ndf = spark.read.options(header='True',inferSchema='True').csv('/FileStore/tables/OfficeData.csv')\ndf.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"29b5e178-e0fb-421d-9826-0c24708f0d52","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|        James|     Sales|   NY| 90000| 34|10000|\n|      Michael|     Sales|   NY| 86000| 56|20000|\n|       Robert|     Sales|   CA| 81000| 30|23000|\n|        Maria|   Finance|   CA| 90000| 24|23000|\n|        Raman|   Finance|   CA| 99000| 40|24000|\n|        Scott|   Finance|   NY| 83000| 36|19000|\n|          Jen|   Finance|   NY| 79000| 53|15000|\n|         Jeff| Marketing|   CA| 80000| 25|18000|\n|        Kumar| Marketing|   NY| 91000| 50|21000|\n+-------------+----------+-----+------+---+-----+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#add new column as Total_salary using UDF\ndef total_sal(salary,bonus):\n    return salary + bonus\n\ntotal_salaryUDF = udf(lambda x,y:total_sal(x,y),IntegerType())\ndf.withColumn('Total_Salary',total_salaryUDF(df.salary,df.bonus)).show()\n# df1.printSchema()\n# df2 = df.withColumn('Total_Salary',total_sal(df.salary,df.bonus))\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"20ac9197-5769-4390-a8f6-8d93d4f53a88","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------------+----------+-----+------+---+-----+------------+\n|employee_name|department|state|salary|age|bonus|Total_Salary|\n+-------------+----------+-----+------+---+-----+------------+\n|        James|     Sales|   NY| 90000| 34|10000|      100000|\n|      Michael|     Sales|   NY| 86000| 56|20000|      106000|\n|       Robert|     Sales|   CA| 81000| 30|23000|      104000|\n|        Maria|   Finance|   CA| 90000| 24|23000|      113000|\n|        Raman|   Finance|   CA| 99000| 40|24000|      123000|\n|        Scott|   Finance|   NY| 83000| 36|19000|      102000|\n|          Jen|   Finance|   NY| 79000| 53|15000|       94000|\n|         Jeff| Marketing|   CA| 80000| 25|18000|       98000|\n|        Kumar| Marketing|   NY| 91000| 50|21000|      112000|\n+-------------+----------+-----+------+---+-----+------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#create new column Increment and provide increment to the emp on following criteria\n#1. If the emp is in NY state, his increment would be 10% of salary and 5% of bonus\n#2. If emp is in CA state, his increment would be 12% of salary and 3% of bonus\nfrom pyspark.sql.types import DoubleType\nfrom pyspark.sql.functions import udf,lit\ndef incSalary(state,salary,bonus):\n    if state == 'NY':\n        return ((salary*0.1)+(bonus*0.05))\n#     elif state == 'CA':\n        return ((salary*0.12) + (bonus*0.03))\n\nincSalUDF = udf(lambda x,y,z:incSalary(x,y,z),DoubleType())\ndf1 = df.withColumn('Increment',incSalUDF(df.state,df.salary,df.bonus))\ndf1.show()\n# df.withColumn('Increment',lit(incSalary(df.state,df.salary,df.bonus))).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"d6357898-5032-4b3a-bf5f-fd48d3036699","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------------+----------+-----+------+---+-----+---------+\n|employee_name|department|state|salary|age|bonus|Increment|\n+-------------+----------+-----+------+---+-----+---------+\n|        James|     Sales|   NY| 90000| 34|10000|   9500.0|\n|      Michael|     Sales|   NY| 86000| 56|20000|   9600.0|\n|       Robert|     Sales|   CA| 81000| 30|23000|     null|\n|        Maria|   Finance|   CA| 90000| 24|23000|     null|\n|        Raman|   Finance|   CA| 99000| 40|24000|     null|\n|        Scott|   Finance|   NY| 83000| 36|19000|   9250.0|\n|          Jen|   Finance|   NY| 79000| 53|15000|   8650.0|\n|         Jeff| Marketing|   CA| 80000| 25|18000|     null|\n|        Kumar| Marketing|   NY| 91000| 50|21000|  10150.0|\n+-------------+----------+-----+------+---+-----+---------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#cache():\n#usually when multiple actions happen (say one after the other) all actions execute the transformations from initial which will eat time.\n# so to optimize it we can execute the cache() after transformations so that when multiple actions execute, action will fetch data from cache #instead of executing all transformations from intial.\ndf.cache()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"7137d959-1358-436f-b198-4e71e8b74c77","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[72]: DataFrame[employee_name: string, department: string, state: string, salary: int, age: int, bonus: int]"]}],"execution_count":0},{"cell_type":"code","source":["df.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"e4644301-85c3-4235-90c4-8909fba499ae","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|        James|     Sales|   NY| 90000| 34|10000|\n|      Michael|     Sales|   NY| 86000| 56|20000|\n|       Robert|     Sales|   CA| 81000| 30|23000|\n|        Maria|   Finance|   CA| 90000| 24|23000|\n|        Raman|   Finance|   CA| 99000| 40|24000|\n|        Scott|   Finance|   NY| 83000| 36|19000|\n|          Jen|   Finance|   NY| 79000| 53|15000|\n|         Jeff| Marketing|   CA| 80000| 25|18000|\n|        Kumar| Marketing|   NY| 91000| 50|21000|\n+-------------+----------+-----+------+---+-----+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["type(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"15aa5a07-1eed-44ed-9e64-7d468b19cd48","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[74]: pyspark.sql.dataframe.DataFrame"]}],"execution_count":0},{"cell_type":"code","source":["#converting DF to RDD\nrdd = df.rdd\ntype(rdd)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"eee8c095-dad1-4435-8eb6-c0b21c1c69e4","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[75]: pyspark.rdd.RDD"]}],"execution_count":0},{"cell_type":"code","source":["rdd.collect()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"44d61af7-f38a-4c5b-af45-bb4ea9433f62","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[76]: [Row(employee_name='James', department='Sales', state='NY', salary=90000, age=34, bonus=10000),\n Row(employee_name='Michael', department='Sales', state='NY', salary=86000, age=56, bonus=20000),\n Row(employee_name='Robert', department='Sales', state='CA', salary=81000, age=30, bonus=23000),\n Row(employee_name='Maria', department='Finance', state='CA', salary=90000, age=24, bonus=23000),\n Row(employee_name='Raman', department='Finance', state='CA', salary=99000, age=40, bonus=24000),\n Row(employee_name='Scott', department='Finance', state='NY', salary=83000, age=36, bonus=19000),\n Row(employee_name='Jen', department='Finance', state='NY', salary=79000, age=53, bonus=15000),\n Row(employee_name='Jeff', department='Marketing', state='CA', salary=80000, age=25, bonus=18000),\n Row(employee_name='Kumar', department='Marketing', state='NY', salary=91000, age=50, bonus=21000)]"]}],"execution_count":0},{"cell_type":"code","source":["rdd.filter(lambda x: x[1] == 'Sales').collect()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"04d432c3-fcfa-4d94-9ddd-e43be8bd4e30","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[77]: [Row(employee_name='James', department='Sales', state='NY', salary=90000, age=34, bonus=10000),\n Row(employee_name='Michael', department='Sales', state='NY', salary=86000, age=56, bonus=20000),\n Row(employee_name='Robert', department='Sales', state='CA', salary=81000, age=30, bonus=23000)]"]}],"execution_count":0},{"cell_type":"code","source":["rdd.filter(lambda x: x['age'] == 34).collect()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"bea39a1e-ec68-4c37-845e-7e4b76398a93","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[78]: [Row(employee_name='James', department='Sales', state='NY', salary=90000, age=34, bonus=10000)]"]}],"execution_count":0},{"cell_type":"code","source":["#Spak SQL\ndf.createOrReplaceTempView('Student')  # create table with student name"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"73310364-44bf-42df-9194-911495f162b5","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["spark.sql(\"select * from student\").show()   #--> spark sql query will return as data frame \n# this is equivalent to \ndf.select('*').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"6d9ce0e8-5d41-45c5-a2a8-b091b4d51ef8","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|        James|     Sales|   NY| 90000| 34|10000|\n|      Michael|     Sales|   NY| 86000| 56|20000|\n|       Robert|     Sales|   CA| 81000| 30|23000|\n|        Maria|   Finance|   CA| 90000| 24|23000|\n|        Raman|   Finance|   CA| 99000| 40|24000|\n|        Scott|   Finance|   NY| 83000| 36|19000|\n|          Jen|   Finance|   NY| 79000| 53|15000|\n|         Jeff| Marketing|   CA| 80000| 25|18000|\n|        Kumar| Marketing|   NY| 91000| 50|21000|\n+-------------+----------+-----+------+---+-----+\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|        James|     Sales|   NY| 90000| 34|10000|\n|      Michael|     Sales|   NY| 86000| 56|20000|\n|       Robert|     Sales|   CA| 81000| 30|23000|\n|        Maria|   Finance|   CA| 90000| 24|23000|\n|        Raman|   Finance|   CA| 99000| 40|24000|\n|        Scott|   Finance|   NY| 83000| 36|19000|\n|          Jen|   Finance|   NY| 79000| 53|15000|\n|         Jeff| Marketing|   CA| 80000| 25|18000|\n|        Kumar| Marketing|   NY| 91000| 50|21000|\n+-------------+----------+-----+------+---+-----+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#Writing a data frame (can use same read command) + while writing df, we need to provide only folder location because spark will write df in partitions  \ndf1.write.options(header='true').csv('/FileStore/tables/officedata/')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"25314230-a6b2-482d-a621-455423fb8a7b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%fs ls /FileStore/tables/officedata/"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"ba252fc3-8c8c-47f7-881c-8965bad24296","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["dbfs:/FileStore/tables/officedata/_SUCCESS","_SUCCESS",0,1686302566000],["dbfs:/FileStore/tables/officedata/_committed_8238028158737769323","_committed_8238028158737769323",112,1686302566000],["dbfs:/FileStore/tables/officedata/_started_8238028158737769323","_started_8238028158737769323",0,1686302565000],["dbfs:/FileStore/tables/officedata/part-00000-tid-8238028158737769323-e9d1d1b6-20f8-4893-bea3-cba05df8ecd1-91-1-c000.csv","part-00000-tid-8238028158737769323-e9d1d1b6-20f8-4893-bea3-cba05df8ecd1-91-1-c000.csv",384,1686302565000]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"path","type":"\"string\"","metadata":"{}"},{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"size","type":"\"long\"","metadata":"{}"},{"name":"modificationTime","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n","  .table-result-container {\n","    max-height: 300px;\n","    overflow: auto;\n","  }\n","  table, th, td {\n","    border: 1px solid black;\n","    border-collapse: collapse;\n","  }\n","  th, td {\n","    padding: 5px;\n","  }\n","  th {\n","    text-align: left;\n","  }\n","</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/FileStore/tables/officedata/_SUCCESS</td><td>_SUCCESS</td><td>0</td><td>1686302566000</td></tr><tr><td>dbfs:/FileStore/tables/officedata/_committed_8238028158737769323</td><td>_committed_8238028158737769323</td><td>112</td><td>1686302566000</td></tr><tr><td>dbfs:/FileStore/tables/officedata/_started_8238028158737769323</td><td>_started_8238028158737769323</td><td>0</td><td>1686302565000</td></tr><tr><td>dbfs:/FileStore/tables/officedata/part-00000-tid-8238028158737769323-e9d1d1b6-20f8-4893-bea3-cba05df8ecd1-91-1-c000.csv</td><td>part-00000-tid-8238028158737769323-e9d1d1b6-20f8-4893-bea3-cba05df8ecd1-91-1-c000.csv</td><td>384</td><td>1686302565000</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["df2 = spark.read.options(header='true').csv('/FileStore/tables/officedata/')\ndf2.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"7f10a24b-5d09-4689-a318-9b7354a3d17d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------------+----------+-----+------+---+-----+---------+\n|employee_name|department|state|salary|age|bonus|Increment|\n+-------------+----------+-----+------+---+-----+---------+\n|        James|     Sales|   NY| 90000| 34|10000|   9500.0|\n|      Michael|     Sales|   NY| 86000| 56|20000|   9600.0|\n|       Robert|     Sales|   CA| 81000| 30|23000|     null|\n|        Maria|   Finance|   CA| 90000| 24|23000|     null|\n|        Raman|   Finance|   CA| 99000| 40|24000|     null|\n|        Scott|   Finance|   NY| 83000| 36|19000|   9250.0|\n|          Jen|   Finance|   NY| 79000| 53|15000|   8650.0|\n|         Jeff| Marketing|   CA| 80000| 25|18000|     null|\n|        Kumar| Marketing|   NY| 91000| 50|21000|  10150.0|\n+-------------+----------+-----+------+---+-----+---------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"58c21cca-87a2-41ba-a02f-827d7b96acc1","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Spark-DF-class","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4,"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":232153205490367,"dataframes":["_sqldf"]}},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
